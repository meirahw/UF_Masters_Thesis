{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/geopython/1.0.1/lib/python3.7/site-packages/pysal/__init__.py:65: VisibleDeprecationWarning: PySAL's API will be changed on 2018-12-31. The last release made with this API is version 1.14.4. A preview of the next API version is provided in the `pysal` 2.0 prelease candidate. The API changes and a guide on how to change imports is provided at https://migrating.pysal.org\n",
      "  ), VisibleDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import os\n",
    "import netCDF4\n",
    "import cartopy\n",
    "from pyproj import CRS, Proj, transform, Transformer\n",
    "import numpy as np\n",
    "import mapclassify\n",
    "import pysal\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### below creates a df categories, damages, and counts of damaging events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "StormData=gpd.read_file(r'/blue/emullens/meirahwilliamson/StormData_shapefile_2/StormData.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill nas with 0 (nas exist if a county never has ff damage)\n",
    "StormData['date']=StormData['date'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create season function\n",
    "def choose_season(season):\n",
    "    csv=pd.read_csv(r'/blue/emullens/meirahwilliamson/netcdf_ero/'+str(season)+'/'+str(season)+'.csv')\n",
    "    csv_fips_index=csv.set_index('FIPS')\n",
    "    return csv_fips_index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add category to each place\n",
    "category_list=[]\n",
    "# check each row, find date, geoid, and season\n",
    "for i in StormData.iterrows():\n",
    "    row=i[1]\n",
    "    geoid=int(row['GEOID'])\n",
    "    date=int(row['date'])\n",
    "    season=row['season']\n",
    "    # no season (i.e. no damages, append with -99)\n",
    "    if season == '' or season==None:\n",
    "        category_list.append(-99)\n",
    "    else:\n",
    "        csv=choose_season(season)\n",
    "        # mising netcdf\n",
    "        if str(date) not in csv:\n",
    "            category_list.append(-50)\n",
    "        #netcdf is there and there are damages yay\n",
    "        else:    \n",
    "            category_list.append(csv[str(date)][geoid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add new category column\n",
    "StormData['category']=category_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5,\n",
       " -99.0,\n",
       " 0.05000000074505806,\n",
       " 0.0,\n",
       " 0.10000000149011612,\n",
       " 0.20000000298023224,\n",
       " -50.0,\n",
       " nan]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure it worked\n",
    "x=StormData['category'].unique()\n",
    "list(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "StormData_nan=StormData.dropna()\n",
    "StormData_v2=StormData_nan[~(StormData_nan['episode_na'].str.contains(\"Harvey|harvey\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "StormData_v2.to_file(r'/blue/emullens/meirahwilliamson/StormData_shapefile_noharvey_riskcat/StormData_nh_rc.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "StormData_v2=gpd.read_file(r'/blue/emullens/meirahwilliamson/StormData_shapefile_noharvey_riskcat/StormData_nh_rc.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 0.050000000745058, 0.0, 0.100000001490116, 0.200000002980232, -50.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure it worked\n",
    "x=StormData_v2['category'].unique()\n",
    "list(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.keys()\n",
    "params = {'axes.labelsize': 30,\n",
    "          'axes.titlesize': 34,\n",
    "          'axes.titlepad': 2,\n",
    "          'xtick.labelsize': 26,\n",
    "         'ytick.labelsize': 26,\n",
    "         'legend.title_fontsize':28,\n",
    "         'legend.fontsize':20}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "subplot_labels=['a)','b)','c)','d)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot causes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(r'/blue/emullens/meirahwilliamson/figures/damage_attribution_risks.png',dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### below creates gdfs for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties=gpd.read_file(r'/blue/emullens/meirahwilliamson/netcdf_ero/county_data/USA_Counties/USA_Counties.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counties=counties[~(counties['STATE_NAME']=='Puerto Rico') & ~(counties['STATE_NAME']=='Alaska')\n",
    "#         & ~(counties['STATE_NAME']=='Hawaii')]\n",
    "# counties=counties.drop(counties.columns[0:6],axis=1)\n",
    "# counties=counties.drop(counties.columns[1:50],axis=1)\n",
    "counties=counties.to_crs(3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties=gpd.read_file(r'/blue/emullens/meirahwilliamson/Shapefiles/US_Counties/US_Counties.shp')\n",
    "counties=counties_2.to_crs(3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_levels_dict={'marginal':0.05000000074505806,\n",
    "                      'slight':0.10000000149011612,\n",
    "                      'moderate':0.20000000298023224,\n",
    "                      'high':0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create gdfs for each category\n",
    "for i in risk_levels_dict:\n",
    "    category=StormData_group_sum_df[StormData_group_sum_df['category']==risk_levels_dict[i]]\n",
    "    merged=pd.merge(counties,category, how='left',left_on=\"GEOID\",right_on='GEOID')\n",
    "    merged.to_file(r'/blue/emullens/meirahwilliamson/StormData_Risk_Categories/'+i+'_damaged_2/'+i+'.shp')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get some stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285571020.0\n",
      "marginal 477543.51170568564 25000.0\n",
      "858195680.0\n",
      "slight 1178840.2197802197 45000.0\n",
      "2953485130.0\n",
      "moderate 8136322.672176309 50000.0\n",
      "42114024860.0\n",
      "high 244848981.74418604 125000.0\n"
     ]
    }
   ],
   "source": [
    "for risk_level in risk_levels_dict:\n",
    "    damaged_counties=gpd.read_file(r'/blue/emullens/meirahwilliamson/StormData_Risk_Categories/'+risk_level+'_damaged/'+risk_level+'.shp')\n",
    "    \n",
    "    mean=damaged_counties['SUM_proper'].mean()\n",
    "    mean_2=damaged_counties[damaged_counties['SUM_proper']!=0]['SUM_proper'].mean()\n",
    "    print(damaged_counties['SUM_proper'].sum())\n",
    "\n",
    "    median=damaged_counties['SUM_proper'].median()\n",
    "    median_2=damaged_counties[damaged_counties['SUM_proper']!=0]['SUM_proper'].median()\n",
    "\n",
    "    \n",
    "    mode=damaged_counties['SUM_proper'].mode()\n",
    "    mode_2=damaged_counties[damaged_counties['SUM_proper']!=0]['SUM_proper'].mode()\n",
    "\n",
    "    print(risk_level,mean_2,median_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>SHAPE_Le_1</th>\n",
       "      <th>SHAPE_Area</th>\n",
       "      <th>GEOID</th>\n",
       "      <th>category</th>\n",
       "      <th>SUM_proper</th>\n",
       "      <th>SUM_crop_d</th>\n",
       "      <th>SUM_prop_c</th>\n",
       "      <th>count</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06053</td>\n",
       "      <td>6.495277</td>\n",
       "      <td>0.860396</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MULTIPOLYGON (((-13520087.681 4283419.790, -13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>06087</td>\n",
       "      <td>2.388135</td>\n",
       "      <td>0.117218</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POLYGON ((-13605624.004 4469113.195, -13605618...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06085</td>\n",
       "      <td>3.933257</td>\n",
       "      <td>0.341450</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MULTIPOLYGON (((-13539883.406 4506615.125, -13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06069</td>\n",
       "      <td>3.718732</td>\n",
       "      <td>0.362726</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POLYGON ((-13534222.246 4424930.701, -13534210...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06111</td>\n",
       "      <td>3.916199</td>\n",
       "      <td>0.471859</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MULTIPOLYGON (((-13306531.467 3933240.934, -13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3103</th>\n",
       "      <td>23025</td>\n",
       "      <td>8.024429</td>\n",
       "      <td>1.221142</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POLYGON ((-7794866.037 5873433.117, -7794461.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>23003</td>\n",
       "      <td>8.081154</td>\n",
       "      <td>2.078769</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POLYGON ((-7703796.789 6016230.645, -7703740.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>23019</td>\n",
       "      <td>6.546183</td>\n",
       "      <td>1.058448</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POLYGON ((-7660933.441 5843985.707, -7657826.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>23021</td>\n",
       "      <td>6.004977</td>\n",
       "      <td>1.313017</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POLYGON ((-7761311.791 5872791.981, -7751600.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3107</th>\n",
       "      <td>23029</td>\n",
       "      <td>17.906018</td>\n",
       "      <td>0.815570</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MULTIPOLYGON (((-7473282.406 5641519.875, -747...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3108 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FIPS  SHAPE_Le_1  SHAPE_Area GEOID  category  SUM_proper  SUM_crop_d  \\\n",
       "0     06053    6.495277    0.860396  None       NaN         NaN         NaN   \n",
       "1     06087    2.388135    0.117218  None       NaN         NaN         NaN   \n",
       "2     06085    3.933257    0.341450  None       NaN         NaN         NaN   \n",
       "3     06069    3.718732    0.362726  None       NaN         NaN         NaN   \n",
       "4     06111    3.916199    0.471859  None       NaN         NaN         NaN   \n",
       "...     ...         ...         ...   ...       ...         ...         ...   \n",
       "3103  23025    8.024429    1.221142  None       NaN         NaN         NaN   \n",
       "3104  23003    8.081154    2.078769  None       NaN         NaN         NaN   \n",
       "3105  23019    6.546183    1.058448  None       NaN         NaN         NaN   \n",
       "3106  23021    6.004977    1.313017  None       NaN         NaN         NaN   \n",
       "3107  23029   17.906018    0.815570  None       NaN         NaN         NaN   \n",
       "\n",
       "      SUM_prop_c  count                                           geometry  \n",
       "0            NaN    NaN  MULTIPOLYGON (((-13520087.681 4283419.790, -13...  \n",
       "1            NaN    NaN  POLYGON ((-13605624.004 4469113.195, -13605618...  \n",
       "2            NaN    NaN  MULTIPOLYGON (((-13539883.406 4506615.125, -13...  \n",
       "3            NaN    NaN  POLYGON ((-13534222.246 4424930.701, -13534210...  \n",
       "4            NaN    NaN  MULTIPOLYGON (((-13306531.467 3933240.934, -13...  \n",
       "...          ...    ...                                                ...  \n",
       "3103         NaN    NaN  POLYGON ((-7794866.037 5873433.117, -7794461.8...  \n",
       "3104         NaN    NaN  POLYGON ((-7703796.789 6016230.645, -7703740.6...  \n",
       "3105         NaN    NaN  POLYGON ((-7660933.441 5843985.707, -7657826.4...  \n",
       "3106         NaN    NaN  POLYGON ((-7761311.791 5872791.981, -7751600.8...  \n",
       "3107         NaN    NaN  MULTIPOLYGON (((-7473282.406 5641519.875, -747...  \n",
       "\n",
       "[3108 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "damaged_counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal 477543.51170568564 25000.0\n",
      "slight 1178840.2197802197 45000.0\n",
      "moderate 8136322.672176309 50000.0\n",
      "high 244848981.74418604 125000.0\n"
     ]
    }
   ],
   "source": [
    "x=[]\n",
    "for risk_level in risk_levels_dict:\n",
    "    damaged_counties=gpd.read_file(r'/blue/emullens/meirahwilliamson/StormData_Risk_Categories/'+risk_level+'_damaged_2/'+risk_level+'.shp')\n",
    "    \n",
    "    mean=damaged_counties['property_d'].mean()\n",
    "    mean_2=damaged_counties[damaged_counties['property_d']!=0]['property_d'].mean()\n",
    "\n",
    "    median=damaged_counties['property_d'].median()\n",
    "    median_2=damaged_counties[damaged_counties['property_d']!=0]['property_d'].median()\n",
    "\n",
    "    \n",
    "    mode=damaged_counties['property_d'].mode()\n",
    "    mode_2=damaged_counties[damaged_counties['property_d']!=0]['property_d'].mode()\n",
    "\n",
    "    x.append(damaged_counties[damaged_counties['property_d']>0]['property_d'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(risk_level,mean_2,median_2)#,fvalue,pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal 477543.51170568564 25000.0\n",
      "slight 1178840.2197802197 45000.0\n",
      "moderate 8136322.672176309 50000.0\n",
      "high 244848981.74418604 125000.0\n"
     ]
    }
   ],
   "source": [
    "x=[]\n",
    "for risk_level in risk_levels_dict:\n",
    "    damaged_counties=gpd.read_file(r'/blue/emullens/meirahwilliamson/StormData_Risk_Categories/'+risk_level+'_damaged_2/'+risk_level+'.shp')\n",
    "    \n",
    "    mean=damaged_counties['property_d'].mean()\n",
    "\n",
    "    median=damaged_counties['property_d'].median()\n",
    "    \n",
    "    mode=damaged_counties['property_d'].mode()\n",
    "\n",
    "    #x.append(damaged_counties[damaged_counties['property_d']>0]['property_d'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(risk_level,mean,median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### missed damaged counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "StormData=gpd.read_file(r'/blue/emullens/meirahwilliamson/StormData_shapefile_2/StormData.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "StormData['date']=StormData['date'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create season function\n",
    "def choose_season(season):\n",
    "    csv=pd.read_csv(r'/blue/emullens/meirahwilliamson/netcdf_ero/'+str(season)+'/'+str(season)+'.csv')\n",
    "    csv_fips_index=csv.set_index('FIPS')\n",
    "    return csv_fips_index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list=[]\n",
    "# check each row, find date, geoid, and season\n",
    "for i in StormData.iterrows():\n",
    "    row=i[1]\n",
    "    geoid=int(row['GEOID'])\n",
    "    date=int(row['date'])\n",
    "    season=row['season']\n",
    "    # no season (i.e. no damages, append with -99)\n",
    "    if season == '' or season==None:\n",
    "        category_list.append(-99)\n",
    "    else:\n",
    "        csv=choose_season(season)\n",
    "        # mising netcdf\n",
    "        if str(date) not in csv:\n",
    "            category_list.append(-50)\n",
    "        #netcdf is there and there are damages yay\n",
    "        else:    \n",
    "            category_list.append(csv[str(date)][geoid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add new category column\n",
    "StormData['category']=category_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sums of damages and count how many times damages occurred \n",
    "StormData_group_sum_df=StormData.groupby(['GEOID','category'])['property_d'].sum().reset_index()\n",
    "StormData_group_count_df=StormData.groupby(['GEOID','category'])['property_d'].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "StormData_group_sum_df['count']=StormData_group_count_df['property_d']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeoPython-1.0.1",
   "language": "python",
   "name": "geopython-1.0.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
